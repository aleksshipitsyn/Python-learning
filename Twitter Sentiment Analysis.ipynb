{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/\n",
    "**Aleksey Shipitsyn**    \n",
    "**2019-08-01**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "id       0\n",
      "label    0\n",
      "tweet    0\n",
      "dtype: int64 \n",
      "\n",
      "shape: (31962, 3) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train data\n",
    "df_train = pd.read_csv('./Documents/Competitions/Twitter Sentiment/train_E6oV3lV.csv') \n",
    "\n",
    "print('Missing values:')\n",
    "print(df_train.isnull().sum(),'\\n')\n",
    "print('shape:', df_train.shape, '\\n')\n",
    "\n",
    "df_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  label\n",
       "label       \n",
       "0       0.93\n",
       "1       0.07"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the balance of target sentiment \n",
    "pd.crosstab(index=df_train.label, columns=['label'], normalize=True).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "id       0\n",
      "tweet    0\n",
      "dtype: int64 \n",
      "\n",
      "shape: (17197, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "df_test = pd.read_csv('./Documents/Competitions/Twitter Sentiment/test_tweets_anuFYb8.csv')\n",
    "\n",
    "print('Missing values:')\n",
    "print(df_test.isnull().sum(),'\\n')\n",
    "print('shape:', df_test.shape, '\\n')\n",
    "\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file matches test set file: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  31963      0\n",
       "1  31964      0\n",
       "2  31965      0\n",
       "3  31966      0\n",
       "4  31967      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read submission data\n",
    "df_submission = pd.read_csv('./Documents/Competitions/Twitter Sentiment/sample_submission_gfvA5FD.xls')\n",
    "\n",
    "# check if submission hash corresponds to test set\n",
    "print('Submission file matches test set file:', all(df_test.id == df_submission.id))\n",
    "\n",
    "df_submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  \n",
    "\n",
    "### Text preprocessing  \n",
    "\n",
    "- Add more features \n",
    "- Remove everything except of english letters\n",
    "- Stopwords  \n",
    "- Stemming \n",
    "- N-grams  \n",
    "- TFIDF  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alekseyshipitsyn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet  words_count  \\\n",
      "0   1      0   @user when a father is dysfunctional and is s...           21   \n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...           22   \n",
      "2   3      0                                bihday your majesty            5   \n",
      "3   4      0  #model   i love u take with u all the time in ...           17   \n",
      "4   5      0             factsguide: society now    #motivation            8   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \n",
      "0         102         4.555556              10         1         0          0  \n",
      "1         122         5.315789               5         3         0          0  \n",
      "2          21         5.666667               1         0         0          0  \n",
      "3          86         4.928571               5         1         0          0  \n",
      "4          39         8.000000               1         1         0          0   \n",
      "\n",
      "      id                                              tweet  words_count  \\\n",
      "0  31963  #studiolife #aislife #requires #passion #dedic...           12   \n",
      "1  31964   @user #white #supremacists want everyone to s...           20   \n",
      "2  31965  safe ways to heal your #acne!!    #altwaystohe...           15   \n",
      "3  31966  is the hp and the cursed child book up for res...           24   \n",
      "4  31967    3rd #bihday to my amazing, hilarious #nephew...           18   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \n",
      "0          90         8.777778               1         7         0          0  \n",
      "1         101         5.125000               4         4         0          0  \n",
      "2          71         6.333333               2         4         0          0  \n",
      "3         142         5.409091               8         3         0          0  \n",
      "4          93         5.066667               4         2         0          0  \n"
     ]
    }
   ],
   "source": [
    "# Add more features\n",
    "\n",
    "train = df_train\n",
    "test = df_test\n",
    "\n",
    "\n",
    "# number of words\n",
    "train['words_count'] = train['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "test['words_count'] = test['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "\n",
    "# number of characters\n",
    "train['char_count'] = train['tweet'].str.len()\n",
    "test['char_count'] = test['tweet'].str.len()\n",
    "\n",
    "\n",
    "# average word length\n",
    "def avg_word_length(sentence):\n",
    "    words = sentence.split()\n",
    "    return sum( len(word) for word in words) / len(words) \n",
    "\n",
    "train['avg_word_length'] = train['tweet'].apply(lambda x: avg_word_length(x))\n",
    "test['avg_word_length'] = test['tweet'].apply(lambda x: avg_word_length(x))\n",
    "\n",
    "\n",
    "# number of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopword_count'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "test['stopword_count'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "\n",
    "# number of special characters\n",
    "train['hashtags'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "test['hashtags'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "\n",
    "# number of numerics\n",
    "train['numerics'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "test['numerics'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "\n",
    "# number od uppercase words\n",
    "train['uppercase'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "test['uppercase'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "print(train[:5], '\\n')\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223, 75)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['numerics'] > 0), sum(train['uppercase'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    user when a father is dysfunctional and is so ...\n",
      "1    user user thanks for lyft credit i can't use c...\n",
      "2                                  bihday your majesty\n",
      "3        model i love u take with u all the time in ur\n",
      "4                    factsguide society now motivation\n",
      "5    huge fan fare and big talking before they leav...\n",
      "6    user camping tomorrow user user user user user...\n",
      "7    the next school year is the year for exams can...\n",
      "8    we won love the land allin cavs champions clev...\n",
      "9                user user welcome here i'm it's so gr\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    studiolife aislife requires passion dedication...\n",
      "1    user white supremacists want everyone to see t...\n",
      "2    safe ways to heal your acne altwaystoheal heal...\n",
      "3    is the hp and the cursed child book up for res...\n",
      "4    rd bihday to my amazing hilarious nephew eli a...\n",
      "5                                 choose to be momtips\n",
      "6    something inside me dies eyes ness smokeyeyes ...\n",
      "7       finished tattoo inked ink loveit thanks aleeee\n",
      "8    user user user i will never understand why my ...\n",
      "9    delicious food lovelife capetown mannaepicure ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove everything but leave english letters and spaces in lower case\n",
    "\n",
    "import re\n",
    "regexp = re.compile('[A-Za-z\\']+')\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join(regexp.findall(x)).lower())\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join(regexp.findall(x)).lower())\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error correction - no big sense here\n",
    "#from textblob import TextBlob\n",
    "\n",
    "#train['tweet'] = train['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "#test['tweet'] = test['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    user father dysfunctional selfish drags kids d...\n",
      "1    user user thanks lyft credit can't use cause o...\n",
      "2                                       bihday majesty\n",
      "3                          model love u take u time ur\n",
      "4                        factsguide society motivation\n",
      "5    huge fan fare big talking leave chaos pay disp...\n",
      "6    user camping tomorrow user user user user user...\n",
      "7    next school year year exams can't think school...\n",
      "8    love land allin cavs champions cleveland cleve...\n",
      "9                             user user welcome i'm gr\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    studiolife aislife requires passion dedication...\n",
      "1    user white supremacists want everyone see new ...\n",
      "2    safe ways heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservations already yes ...\n",
      "4    rd bihday amazing hilarious nephew eli ahmir u...\n",
      "5                                       choose momtips\n",
      "6    something inside dies eyes ness smokeyeyes tir...\n",
      "7       finished tattoo inked ink loveit thanks aleeee\n",
      "8    user user user never understand dad left young...\n",
      "9    delicious food lovelife capetown mannaepicure ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed words: ['user', 'love', 'day', 'amp', 'happy', 'u', 'like', 'life', 'time', 'today']\n",
      "\n",
      "0    father dysfunctional selfish drags kids dysfun...\n",
      "1    thanks lyft credit can't use cause offer wheel...\n",
      "2                                       bihday majesty\n",
      "3                                        model take ur\n",
      "4                        factsguide society motivation\n",
      "5    huge fan fare big talking leave chaos pay disp...\n",
      "6                               camping tomorrow danny\n",
      "7    next school year year exams can't think school...\n",
      "8    land allin cavs champions cleveland clevelandc...\n",
      "9                                       welcome i'm gr\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    studiolife aislife requires passion dedication...\n",
      "1    white supremacists want everyone see new birds...\n",
      "2    safe ways heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservations already yes ...\n",
      "4    rd bihday amazing hilarious nephew eli ahmir u...\n",
      "5                                       choose momtips\n",
      "6    something inside dies eyes ness smokeyeyes tir...\n",
      "7       finished tattoo inked ink loveit thanks aleeee\n",
      "8      never understand dad left young deep inthefeels\n",
      "9    delicious food lovelife capetown mannaepicure ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# words frequencies\n",
    "freq = pd.Series(\" \".join(train['tweet']).split()).value_counts() \n",
    "\n",
    "# 10 most frequent words\n",
    "freq_words = list(freq.index[:10])\n",
    "print('Removed words: {}\\n'.format(freq_words))\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join([x for x in x.split() if x not in freq_words]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join([x for x in x.split() if x not in freq_words]))\n",
    "\n",
    "# remove most frequent words from frequency list \n",
    "freq = freq[10:]\n",
    "\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        father dysfunct selfish drag kid dysfunct run\n",
      "1    thank lyft credit can't use caus offer wheelch...\n",
      "2                                       bihday majesti\n",
      "3                                        model take ur\n",
      "4                              factsguid societi motiv\n",
      "5    huge fan fare big talk leav chao pay disput ge...\n",
      "6                                  camp tomorrow danni\n",
      "7    next school year year exam can't think school ...\n",
      "8    land allin cav champion cleveland clevelandcavali\n",
      "9                                        welcom i'm gr\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    studiolif aislif requir passion dedic willpow ...\n",
      "1     white supremacist want everyon see new bird movi\n",
      "2            safe way heal acn altwaystoh healthi heal\n",
      "3    hp curs child book reserv alreadi ye harrypott...\n",
      "4    rd bihday amaz hilari nephew eli ahmir uncl da...\n",
      "5                                         choos momtip\n",
      "6    someth insid die eye ness smokeyey tire lone s...\n",
      "7             finish tattoo ink ink loveit thank aleee\n",
      "8       never understand dad left young deep inthefeel\n",
      "9      delici food lovelif capetown mannaepicur restur\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet  words_count  \\\n",
      "0   1      0      father dysfunct selfish drag kid dysfunct run           21   \n",
      "1   2      0  thank lyft credit can't use caus offer wheelch...           22   \n",
      "2   3      0                                     bihday majesti            5   \n",
      "3   4      0                                      model take ur           17   \n",
      "4   5      0                            factsguid societi motiv            8   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \\\n",
      "0         102         4.555556              10         1         0          0   \n",
      "1         122         5.315789               5         3         0          0   \n",
      "2          21         5.666667               1         0         0          0   \n",
      "3          86         4.928571               5         1         0          0   \n",
      "4          39         8.000000               1         1         0          0   \n",
      "\n",
      "   TextBlob_sentiment  \n",
      "0                -0.3  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0   \n",
      "\n",
      "      id                                              tweet  words_count  \\\n",
      "0  31963  studiolif aislif requir passion dedic willpow ...           12   \n",
      "1  31964   white supremacist want everyon see new bird movi           20   \n",
      "2  31965          safe way heal acn altwaystoh healthi heal           15   \n",
      "3  31966  hp curs child book reserv alreadi ye harrypott...           24   \n",
      "4  31967  rd bihday amaz hilari nephew eli ahmir uncl da...           18   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \\\n",
      "0          90         8.777778               1         7         0          0   \n",
      "1         101         5.125000               4         4         0          0   \n",
      "2          71         6.333333               2         4         0          0   \n",
      "3         142         5.409091               8         3         0          0   \n",
      "4          93         5.066667               4         2         0          0   \n",
      "\n",
      "   TextBlob_sentiment  \n",
      "0            0.000000  \n",
      "1            0.068182  \n",
      "2            0.500000  \n",
      "3            0.000000  \n",
      "4            0.500000  \n"
     ]
    }
   ],
   "source": [
    "# TextBlob sentiment feature \n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "train['TextBlob_sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "test['TextBlob_sentiment'] = test['tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "\n",
    "print(train[:5], '\\n')\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21414, 9), (21414,), (10548, 9), (10548,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training data to training and validation subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train[[col for col in train.columns if (col != 'id') & (col != 'label')]]\n",
    "y = train['label'].values.astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21414, 24532), (10548, 24532))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF with N-grams\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), lowercase=False)\n",
    "\n",
    "X_train_txt_features = vect.fit_transform(X_train['tweet'])\n",
    "X_test_txt_features = vect.transform(X_test['tweet'])\n",
    "\n",
    "X_train_txt_features.shape, X_test_txt_features.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training set: 0.947\n",
      "Score for validation set: 0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseyshipitsyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "model.fit(X_train_txt_features, y_train)\n",
    "\n",
    "model_sentiment = model.predict(X_train_txt_features)\n",
    "\n",
    "print('Score for training set: {}'.format(model.score(X_train_txt_features, y_train).round(3)))\n",
    "print('Score for validation set: {}'.format(model.score(X_test_txt_features, y_test).round(3)))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (31962, 31497) (17197, 31497)\n",
      "Score for training set: 0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseyshipitsyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# retrain the model on all training data\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = test[[col for col in test.columns if (col != 'id')]]\n",
    "\n",
    "X_train_txt_features = vect.fit_transform(X_train['tweet'])\n",
    "X_test_txt_features = vect.transform(X_test['tweet'])\n",
    "\n",
    "print('Data shape:', X_train_txt_features.shape, X_test_txt_features.shape)\n",
    "\n",
    "model.fit(X_train_txt_features, y_train)\n",
    "print('Score for training set: {}'.format(model.score(X_train_txt_features, y_train).round(3)))\n",
    "\n",
    "train_sentiment = model.predict(X_train_txt_features)\n",
    "test_sentiment = model.predict(X_test_txt_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>uppercase</th>\n",
       "      <th>TextBlob_sentiment</th>\n",
       "      <th>model_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words_count  char_count  avg_word_length  stopword_count  hashtags  \\\n",
       "0           21         102         4.555556              10         1   \n",
       "1           22         122         5.315789               5         3   \n",
       "2            5          21         5.666667               1         0   \n",
       "3           17          86         4.928571               5         1   \n",
       "4            8          39         8.000000               1         1   \n",
       "\n",
       "   numerics  uppercase  TextBlob_sentiment model_sentiment  \n",
       "0         0          0                -0.3               0  \n",
       "1         0          0                 0.0               0  \n",
       "2         0          0                 0.0               0  \n",
       "3         0          0                 0.0               0  \n",
       "4         0          0                 0.0               0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack sentiment predictions with other features\n",
    "X_train = X_train.drop('tweet', axis='columns')\n",
    "X_test = X_test.drop('tweet', axis='columns')\n",
    "\n",
    "X_train['model_sentiment'] = train_sentiment\n",
    "X_test['model_sentiment'] = test_sentiment\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training set: 0.942\n"
     ]
    }
   ],
   "source": [
    "# Stack model\n",
    "stack_model = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "\n",
    "stack_model.fit(X_train, y_train)\n",
    "print('Score for training set: {}'.format(stack_model.score(X_train, y_train).round(3)))\n",
    "\n",
    "prediction = stack_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  label\n",
      "0  31963      0\n",
      "1  31964      1\n",
      "2  31965      0\n",
      "3  31966      0\n",
      "4  31967      0\n"
     ]
    }
   ],
   "source": [
    "df_submission['label'] = prediction.astype(int)\n",
    "print(df_submission.head())\n",
    "\n",
    "df_submission.to_csv('./Documents/Competitions/Twitter Sentiment/submission_1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acheaved rank is 408 from 10321 participants, or top 3.95 %\n"
     ]
    }
   ],
   "source": [
    "# rank at submission\n",
    "rank = 408\n",
    "participants = 10321\n",
    "print('Acheaved rank is {} from {} participants, or top {} %'.format(\n",
    "            rank, participants, round(100*rank/participants, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
