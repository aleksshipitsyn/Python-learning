{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the Sentiments  \n",
    "https://datahack.analyticsvidhya.com/contest/linguipedia-codefest-natural-language-processing-1/  \n",
    "**Aleksey Shipitsyn**    \n",
    "**2019-08-02**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "id       0\n",
      "label    0\n",
      "tweet    0\n",
      "dtype: int64 \n",
      "\n",
      "shape: (7920, 3) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train data\n",
    "df_train = pd.read_csv('./Documents/Competitions/Identify Sentiments/train_2kmZucJ.xls') \n",
    "\n",
    "print('Missing values:')\n",
    "print(df_train.isnull().sum(),'\\n')\n",
    "print('shape:', df_train.shape, '\\n')\n",
    "\n",
    "df_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  label\n",
       "label       \n",
       "0       0.74\n",
       "1       0.26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the balance of target sentiment \n",
    "pd.crosstab(index=df_train.label, columns=['label'], normalize=True).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "id       0\n",
      "tweet    0\n",
      "dtype: int64 \n",
      "\n",
      "shape: (1953, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1  7922  currently shitting my fucking pants. #apple #i...\n",
       "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3  7924  My ipod is officially dead. I lost all my pict...\n",
       "4  7925  Been fighting iTunes all night! I only want th..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "df_test = pd.read_csv('./Documents/Competitions/Identify Sentiments/test_oJQbWVk.xls')\n",
    "\n",
    "print('Missing values:')\n",
    "print(df_test.isnull().sum(),'\\n')\n",
    "print('shape:', df_test.shape, '\\n')\n",
    "\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file matches test set file: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0  7921      0\n",
       "1  7922      0\n",
       "2  7923      0\n",
       "3  7924      0\n",
       "4  7925      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read submission data\n",
    "df_submission = pd.read_csv('./Documents/Competitions/Identify Sentiments/sample_submission_LnhVWA4.xls')\n",
    "\n",
    "# check if submission hash corresponds to test set\n",
    "print('Submission file matches test set file:', all(df_test.id == df_submission.id))\n",
    "\n",
    "df_submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  \n",
    "\n",
    "### Text preprocessing  \n",
    "\n",
    "- Add more features \n",
    "- Remove everything except of english letters\n",
    "- Stopwords  \n",
    "- Stemming \n",
    "- N-grams  \n",
    "- TFIDF  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alekseyshipitsyn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet  words_count  \\\n",
      "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...           13   \n",
      "1   2      0  Finally a transparant silicon case ^^ Thanks t...           17   \n",
      "2   3      0  We love this! Would you go? #talk #makememorie...           15   \n",
      "3   4      0  I'm wired I know I'm George I was made that wa...           17   \n",
      "4   5      1  What amazing service! Apple won't even talk to...           23   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \n",
      "0         128         8.923077               0        11         0          0  \n",
      "1         131         6.764706               3         5         0          1  \n",
      "2         123         7.266667               1         8         0          0  \n",
      "3         112         5.647059               2         4         0          2  \n",
      "4         124         4.434783               9         0         0          2   \n",
      "\n",
      "     id                                              tweet  words_count  \\\n",
      "0  7921  I hate the new #iphone upgrade. Won't let me d...           14   \n",
      "1  7922  currently shitting my fucking pants. #apple #i...           11   \n",
      "2  7923  I'd like to puts some CD-ROMS on my iPad, is t...           20   \n",
      "3  7924  My ipod is officially dead. I lost all my pict...           23   \n",
      "4  7925  Been fighting iTunes all night! I only want th...           14   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \n",
      "0          77         4.571429               2         3         0          1  \n",
      "1         115         9.545455               1         5         0          0  \n",
      "2         104         4.200000              10         0         0          1  \n",
      "3         129         4.652174               8         2         0          2  \n",
      "4          70         4.071429               4         0         0          2  \n"
     ]
    }
   ],
   "source": [
    "# Add more features\n",
    "\n",
    "train = df_train\n",
    "test = df_test\n",
    "\n",
    "\n",
    "# number of words\n",
    "train['words_count'] = train['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "test['words_count'] = test['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "\n",
    "# number of characters\n",
    "train['char_count'] = train['tweet'].str.len()\n",
    "test['char_count'] = test['tweet'].str.len()\n",
    "\n",
    "\n",
    "# average word length\n",
    "def avg_word_length(sentence):\n",
    "    words = sentence.split()\n",
    "    return sum( len(word) for word in words) / len(words) \n",
    "\n",
    "train['avg_word_length'] = train['tweet'].apply(lambda x: avg_word_length(x))\n",
    "test['avg_word_length'] = test['tweet'].apply(lambda x: avg_word_length(x))\n",
    "\n",
    "\n",
    "# number of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopword_count'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "test['stopword_count'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "\n",
    "# number of special characters\n",
    "train['hashtags'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "test['hashtags'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "\n",
    "# number of numerics\n",
    "train['numerics'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "test['numerics'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "\n",
    "# number od uppercase words\n",
    "train['uppercase'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "test['uppercase'] = test['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "print(train[:5], '\\n')\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 3146)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train['numerics'] > 0), sum(train['uppercase'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fingerprint pregnancy test https goo gl h mfqv...\n",
      "1    finally a transparant silicon case thanks to m...\n",
      "2    we love this would you go talk makememories un...\n",
      "3    i'm wired i know i'm george i was made that wa...\n",
      "4    what amazing service apple won't even talk to ...\n",
      "5    iphone software update fucked up my phone big ...\n",
      "6    happy for us instapic instadaily us sony xperi...\n",
      "7    new type c charger cable uk http www ebay co u...\n",
      "8    bout to go shopping again listening to music i...\n",
      "9    photo fun selfie pool water sony camera picoft...\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    i hate the new iphone upgrade won't let me dow...\n",
      "1    currently shitting my fucking pants apple imac...\n",
      "2    i'd like to puts some cd roms on my ipad is th...\n",
      "3    my ipod is officially dead i lost all my pictu...\n",
      "4    been fighting itunes all night i only want the...\n",
      "5    repost getbakednfried with repostapp to announ...\n",
      "6    this new apple software update is really doing...\n",
      "7    baby iphone iphone s gold new apple appleisbes...\n",
      "8    i'm confused why did i have to take the time t...\n",
      "9    fruit just tastes better when you pick it your...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove everything but leave english letters and spaces in lower case\n",
    "\n",
    "import re\n",
    "regexp = re.compile('[A-Za-z\\']+')\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join(regexp.findall(x)).lower())\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join(regexp.findall(x)).lower())\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error correction - no big sense here\n",
    "\n",
    "#from textblob import TextBlob\n",
    "#train['tweet'] = train['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "#test['tweet'] = test['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fingerprint pregnancy test https goo gl h mfqv...\n",
      "1    finally transparant silicon case thanks uncle ...\n",
      "2    love would go talk makememories unplug relax i...\n",
      "3    i'm wired know i'm george made way iphone cute...\n",
      "4    amazing service apple even talk question unles...\n",
      "5    iphone software update fucked phone big time s...\n",
      "6    happy us instapic instadaily us sony xperia xp...\n",
      "7    new type c charger cable uk http www ebay co u...\n",
      "8    bout go shopping listening music iphone justme...\n",
      "9    photo fun selfie pool water sony camera picoft...\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0    hate new iphone upgrade let download apps ugh ...\n",
      "1    currently shitting fucking pants apple imac ca...\n",
      "2    i'd like puts cd roms ipad possible ' yes bloc...\n",
      "3    ipod officially dead lost pictures videos sos ...\n",
      "4                fighting itunes night want music paid\n",
      "5    repost getbakednfried repostapp announce apple...\n",
      "6    new apple software update really things phone ...\n",
      "7    baby iphone iphone gold new apple appleisbest ...\n",
      "8    i'm confused take time set appointment still w...\n",
      "9    fruit tastes better pick apple healthy fruit n...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed words: ['iphone', 'http', 'com', 'apple', 'p', 'instagram', 'samsung', 'twitter', 'new', 'https']\n",
      "\n",
      "0    fingerprint pregnancy test goo gl h mfqv andro...\n",
      "1    finally transparant silicon case thanks uncle ...\n",
      "2    love would go talk makememories unplug relax s...\n",
      "3    i'm wired know i'm george made way cute davent...\n",
      "4    amazing service even talk question unless pay ...\n",
      "5    software update fucked phone big time stupid i...\n",
      "6    happy us instapic instadaily us sony xperia xp...\n",
      "7    type c charger cable uk www ebay co uk itm bay...\n",
      "8    bout go shopping listening music justme music ...\n",
      "9    photo fun selfie pool water sony camera picoft...\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0             hate upgrade let download apps ugh sucks\n",
      "1    currently shitting fucking pants imac cashmone...\n",
      "2    i'd like puts cd roms ipad possible ' yes bloc...\n",
      "3    ipod officially dead lost pictures videos sos ...\n",
      "4                fighting itunes night want music paid\n",
      "5    repost getbakednfried repostapp announce bourb...\n",
      "6       software update really things phone bad things\n",
      "7    baby gold appleisbest gb geg nnt aaaaah www ba...\n",
      "8    i'm confused take time set appointment still w...\n",
      "9    fruit tastes better pick healthy fruit nyc ift...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# words frequencies\n",
    "freq = pd.Series(\" \".join(train['tweet']).split()).value_counts() \n",
    "\n",
    "# 10 most frequent words\n",
    "freq_words = list(freq.index[:10])\n",
    "print('Removed words: {}\\n'.format(freq_words))\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join([x for x in x.split() if x not in freq_words]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join([x for x in x.split() if x not in freq_words]))\n",
    "\n",
    "# remove most frequent words from frequency list \n",
    "freq = freq[10:]\n",
    "\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fingerprint pregnanc test goo gl h mfqv androi...\n",
      "1    final transpar silicon case thank uncl yay son...\n",
      "2    love would go talk makememori unplug relax sma...\n",
      "3    i'm wire know i'm georg made way cute daventri...\n",
      "4    amaz servic even talk question unless pay stup...\n",
      "5       softwar updat fuck phone big time stupid iphon\n",
      "6    happi us instap instadaili us soni xperia xper...\n",
      "7    type c charger cabl uk www ebay co uk itm bay ...\n",
      "8    bout go shop listen music justm music likeforl...\n",
      "9    photo fun selfi pool water soni camera picofth...\n",
      "Name: tweet, dtype: object \n",
      "\n",
      "0                hate upgrad let download app ugh suck\n",
      "1    current shit fuck pant imac cashmoney raddest ...\n",
      "2    i'd like put cd rom ipad possibl ' ye block sc...\n",
      "3    ipod offici dead lost pictur video so concert ...\n",
      "4                     fight itun night want music paid\n",
      "5    repost getbakednfri repostapp announc bourbon ...\n",
      "6           softwar updat realli thing phone bad thing\n",
      "7    babi gold appleisbest gb geg nnt aaaaah www ba...\n",
      "8    i'm confus take time set appoint still wait mi...\n",
      "9    fruit tast better pick healthi fruit nyc ift t...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "print(train['tweet'][:10], '\\n')\n",
    "print(test['tweet'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet  words_count  \\\n",
      "0   1      0  fingerprint pregnanc test goo gl h mfqv androi...           13   \n",
      "1   2      0  final transpar silicon case thank uncl yay son...           17   \n",
      "2   3      0  love would go talk makememori unplug relax sma...           15   \n",
      "3   4      0  i'm wire know i'm georg made way cute daventri...           17   \n",
      "4   5      1  amaz servic even talk question unless pay stup...           23   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \\\n",
      "0         128         8.923077               0        11         0          0   \n",
      "1         131         6.764706               3         5         0          1   \n",
      "2         123         7.266667               1         8         0          0   \n",
      "3         112         5.647059               2         4         0          2   \n",
      "4         124         4.434783               9         0         0          2   \n",
      "\n",
      "   TextBlob_sentiment  \n",
      "0                 0.5  \n",
      "1                 0.0  \n",
      "2                 0.5  \n",
      "3                 0.5  \n",
      "4                -0.8   \n",
      "\n",
      "     id                                              tweet  words_count  \\\n",
      "0  7921              hate upgrad let download app ugh suck           14   \n",
      "1  7922  current shit fuck pant imac cashmoney raddest ...           11   \n",
      "2  7923  i'd like put cd rom ipad possibl ' ye block sc...           20   \n",
      "3  7924  ipod offici dead lost pictur video so concert ...           23   \n",
      "4  7925                   fight itun night want music paid           14   \n",
      "\n",
      "   char_count  avg_word_length  stopword_count  hashtags  numerics  uppercase  \\\n",
      "0          77         4.571429               2         3         0          1   \n",
      "1         115         9.545455               1         5         0          0   \n",
      "2         104         4.200000              10         0         0          1   \n",
      "3         129         4.652174               8         2         0          2   \n",
      "4          70         4.071429               4         0         0          2   \n",
      "\n",
      "   TextBlob_sentiment  \n",
      "0                -0.8  \n",
      "1                -0.2  \n",
      "2                 0.0  \n",
      "3                -0.2  \n",
      "4                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# TextBlob sentiment feature \n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "train['TextBlob_sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "test['TextBlob_sentiment'] = test['tweet'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "\n",
    "print(train[:5], '\\n')\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5306, 9), (5306,), (2614, 9), (2614,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training data to training and validation subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train[[col for col in train.columns if (col != 'id') & (col != 'label')]]\n",
    "y = train['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5306, 105665), (2614, 105665))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF with N-grams\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(1,3), lowercase=False)\n",
    "\n",
    "X_train_txt_features = vect.fit_transform(X_train['tweet'])\n",
    "X_test_txt_features = vect.transform(X_test['tweet'])\n",
    "\n",
    "X_train_txt_features.shape, X_test_txt_features.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1, class_weight='balanced')\n",
    "\n",
    "model.fit(X_train_txt_features, y_train)\n",
    "\n",
    "model_sentiment = model.predict(X_train_txt_features)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training set: 0.933048433048433\n",
      "Score for validation set: 0.8028442146089204\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_train = f1_score(y_true=y_train, y_pred=model.predict(X_train_txt_features))\n",
    "f1_validation = f1_score(y_true=y_test, y_pred=model.predict(X_test_txt_features))\n",
    "\n",
    "\n",
    "print('Score for training set: {}'.format(f1_train))\n",
    "print('Score for validation set: {}'.format(f1_validation))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7920, 150631) (1953, 150631)\n",
      "Score for training set: 0.9249193919852602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseyshipitsyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# retrain the model on all training data\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = test[[col for col in test.columns if (col != 'id')]]\n",
    "\n",
    "X_train_txt_features = vect.fit_transform(X_train['tweet'])\n",
    "X_test_txt_features = vect.transform(X_test['tweet'])\n",
    "\n",
    "print('Data shape:', X_train_txt_features.shape, X_test_txt_features.shape)\n",
    "\n",
    "model.fit(X_train_txt_features, y_train)\n",
    "\n",
    "f1_train = f1_score(y_true=y_train, y_pred=model.predict(X_train_txt_features))\n",
    "print('Score for training set: {}'.format(f1_train))\n",
    "\n",
    "train_sentiment = model.predict(X_train_txt_features)\n",
    "test_sentiment = model.predict(X_test_txt_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>uppercase</th>\n",
       "      <th>TextBlob_sentiment</th>\n",
       "      <th>model_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>8.923077</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>131</td>\n",
       "      <td>6.764706</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>123</td>\n",
       "      <td>7.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>112</td>\n",
       "      <td>5.647059</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>124</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words_count  char_count  avg_word_length  stopword_count  hashtags  \\\n",
       "0           13         128         8.923077               0        11   \n",
       "1           17         131         6.764706               3         5   \n",
       "2           15         123         7.266667               1         8   \n",
       "3           17         112         5.647059               2         4   \n",
       "4           23         124         4.434783               9         0   \n",
       "\n",
       "   numerics  uppercase  TextBlob_sentiment  model_sentiment  \n",
       "0         0          0                 0.5                0  \n",
       "1         0          1                 0.0                0  \n",
       "2         0          0                 0.5                0  \n",
       "3         0          2                 0.5                0  \n",
       "4         0          2                -0.8                1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack sentiment predictions with other features\n",
    "X_train = X_train.drop('tweet', axis='columns')\n",
    "X_test = X_test.drop('tweet', axis='columns')\n",
    "\n",
    "X_train['model_sentiment'] = train_sentiment\n",
    "X_test['model_sentiment'] = test_sentiment\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training set: 0.9249193919852602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseyshipitsyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Stack model\n",
    "stack_model = LogisticRegression(C=1, class_weight='balanced')\n",
    "\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "f1_stack = f1_score(y_true=y_train, y_pred=stack_model.predict(X_train))\n",
    "print('Score for training set: {}'.format(f1_stack))\n",
    "\n",
    "prediction = stack_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  label\n",
      "0  7921      1\n",
      "1  7922      1\n",
      "2  7923      1\n",
      "3  7924      1\n",
      "4  7925      1\n"
     ]
    }
   ],
   "source": [
    "df_submission['label'] = prediction.astype(int)\n",
    "print(df_submission.head())\n",
    "\n",
    "df_submission.to_csv('./Documents/Competitions/Identify Sentiments/submission_1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acheaved rank is 225 from 2424 participants, or top 9.28 %\n"
     ]
    }
   ],
   "source": [
    "# rank at submission\n",
    "rank = 225\n",
    "participants = 2424\n",
    "print('Acheaved rank is {} from {} participants, or top {} %'.format(\n",
    "            rank, participants, round(100*rank/participants, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
